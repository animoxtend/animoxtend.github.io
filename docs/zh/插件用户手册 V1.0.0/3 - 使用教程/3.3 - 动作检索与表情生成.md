# 3.3 - 动作检索与表情生成

## 概述

AnimoXtend内置了庞大的数字角色动作库（4000+），同时支持通过输入音频的方式生成角色的面部表情动画，用户可以在Blender中便捷地搜索/生成动画，并将其应用在自定义的角色上

用户可以在AX_Animate中的Generate子模块下完成动作检索与表情生成操作，点击键盘N按键展开Blender的N-Panel

在N-Panel中找到”AX_Animate”选项卡，在选项卡下展开”Generate“子模块

![image.png](https://prod-files-secure.s3.us-west-2.amazonaws.com/377f2602-1acb-4b9b-b8c9-0b4eab3f6e7a/433d1eb1-25e3-4607-bbad-8197d3582438/image.png)

## 动作检索

首先将Generate子模块调节到动作生成（Motion）模式。
执行动作检索可以按如下操作步骤（<span class="red">必须</span> | <span class="orange">可选</span> | <span class="purple">进阶</span>）：

![image.png](https://prod-files-secure.s3.us-west-2.amazonaws.com/377f2602-1acb-4b9b-b8c9-0b4eab3f6e7a/1464e940-7a4d-4d8d-b5ea-a1245b4deb32/image.png)

1. <span class="red">角色选择（Target Armature）</span>
    - 您需要选择一个带有动画数据的对象来作为 目标角色（Target Armature）。您可以在场景中选中目标角色，然后点击吸管工具对Armature进行赋值

    ![image.png](https://prod-files-secure.s3.us-west-2.amazonaws.com/377f2602-1acb-4b9b-b8c9-0b4eab3f6e7a/9d4e6571-a601-412f-a2e1-c1e3b1b594cd/image.png)

2. <span class="purple">开启位置锁定</span>
    - 点击吸管工具右侧的圆点工具，在Target Armature上存在动画的情况下，新导入的动画会以旧动画的重点位置作为动作的起点

    ![image.png](https://prod-files-secure.s3.us-west-2.amazonaws.com/377f2602-1acb-4b9b-b8c9-0b4eab3f6e7a/fe9290b6-712b-4724-bfe2-5133ed441045/image.png)

3. <span class="red">键入动作文本（Text）</span>
    - 在Text文本框中输入动作的描述（支持中英文），按下回车后开始搜索相关动作

    ![image.png](https://prod-files-secure.s3.us-west-2.amazonaws.com/377f2602-1acb-4b9b-b8c9-0b4eab3f6e7a/6ca8bba3-cf2e-4d58-9719-d2ac976c1324/image.png)

4. <span class="orange">调节检索数量</span>
    - 调节Text输入框右侧的滑条，可以设置显示在检索列表中动作的数量

    ![image.png](https://prod-files-secure.s3.us-west-2.amazonaws.com/377f2602-1acb-4b9b-b8c9-0b4eab3f6e7a/1c61ceba-34d1-42f8-888c-41c190728c2b/image.png)

5. <span class="orange">刷新检索列表（Search）</span>
    - 点击Search按键，可以重复刷新检索列表

    ![image.png](https://prod-files-secure.s3.us-west-2.amazonaws.com/377f2602-1acb-4b9b-b8c9-0b4eab3f6e7a/62eeb756-9ecc-4b29-a375-3f131429b301/image.png)

6. <span class="red">选择检索结果（Motion）</span>
    - 在Motion下拉菜单中选择检索到的动作，默认选择最顶部的动作（暂时不支持在下拉菜单中预览动作）

    ![image.png](https://prod-files-secure.s3.us-west-2.amazonaws.com/377f2602-1acb-4b9b-b8c9-0b4eab3f6e7a/6ca88eee-9545-4919-a5de-4051b3c549f8/image.png)

7. <span class="red">导入动作（Generate Motion Anim）</span>
    - 点击Generate Motion Anim 按键，即可将当前Motion下拉菜单中选择的动画设定到Target Armature上

    ![image.png](https://prod-files-secure.s3.us-west-2.amazonaws.com/377f2602-1acb-4b9b-b8c9-0b4eab3f6e7a/277d085a-7e6f-43b6-a35c-2f85aabf6767/image.png)

> [!TIP] 💡 Tips
> 按键的上方会提示当前的交互状态，如不满足执行条件，将无法触发该按键

8. <span class="purple">动作检查</span>
    - 若导入的动作存在问题，需要在Outliner窗口中，找到Template Collection，将其设置为Viewport Visible

    ![image.png](https://prod-files-secure.s3.us-west-2.amazonaws.com/377f2602-1acb-4b9b-b8c9-0b4eab3f6e7a/ff16ca33-0521-4c98-8ab2-ffa3955c768d/image.png)

    - 在Viewport的世界原点位置，将展示Template Collection中的Buffer Armature
    - 若Buffer Armature上动画正常，但Target Armature上动画错误，需要手动进行[👥 动作重定向](https://www.notion.so/176ec1cf5e3e80a4ac9ddeefc53b2bcf?pvs=21)
    - 若Buffer Armature上动作错误，请联系开发者[:wechat: 微信1群：](https://www.notion.so/1-176ec1cf5e3e8030b07fe5bdfb8bc71c?pvs=21)

## 表情生成

首先将Generate子模块调节到表情生成（Face）模式。
执行动作检索可以按如下操作步骤（<span class="red">必须</span> | <span class="orange">可选</span> | <span class="purple">进阶</span>）：

![image.png](https://prod-files-secure.s3.us-west-2.amazonaws.com/377f2602-1acb-4b9b-b8c9-0b4eab3f6e7a/004375af-3c52-46f5-a484-181523f3f5ba/image.png)

1. <span class="red">面部选择（Target Face Mesh）</span>
    - 您需要选择一个带有动画数据的对象来作为 目标人脸（Target Face Mesh）。您可以在场景中选中目标网格，然后点击吸管工具对Face Mesh进行赋值

    ![image.png](https://prod-files-secure.s3.us-west-2.amazonaws.com/377f2602-1acb-4b9b-b8c9-0b4eab3f6e7a/daabf304-db4d-4563-886d-c3197f6cdeca/image.png)

> [!TIP] 💡 Tips
> Target Face Mesh上需要包含标准的Arkit 52维表情基，如果对象上没有shapekey，或者shapekey 命名不匹配，表情生成功能会执行失败（shapekey的命名规范可以参考Template Collection中的Buffer Human）

2. <span class="red">选择音频路径（Audio Path）</span>
    - 点击文件夹图标选择音频文件，或填入音频文件的路径

    ![image.png](https://prod-files-secure.s3.us-west-2.amazonaws.com/377f2602-1acb-4b9b-b8c9-0b4eab3f6e7a/f173e2ab-0e4e-4240-96f8-278aa0a263f4/image.png)

> [!TIP] 💡 Tips
> 文件夹名称不得包含中文字符，需使用绝对路径，目前仅支持.wav格式的音频文件

3. <span class="red">导入表情动画（Generate Face Anim）</span>
    - 点击Generate Face Anim按键，即可从音频生成表情动画，并设置在Target Face Mesh上

    ![image.png](https://prod-files-secure.s3.us-west-2.amazonaws.com/377f2602-1acb-4b9b-b8c9-0b4eab3f6e7a/f173e2ab-0e4e-4240-96f8-278aa0a263f4/image.png)

    > [!TIP] 💡 Tips
    > 按键的上方会提示当前的交互状态，如不满足执行条件，将无法触发该按键

4. <span class="purple">进阶设置（Advanced）</span>
    - 点击Advanced菜单，可以展开Face模式的进阶设置，主要用于表情生成功能相关的增量设置和单步调试
    - 点击*Face Model*最右侧的刷新按钮，可以获取目前最新的audio2face模型列表，在下拉菜单中选择对应的模型，即可进行下一步操作
    - 名称中包含“*emo*”词缀的Face Model支持情绪的选择，可以在*Emotion*下拉菜单中选择想要使用的表情情绪
    - Audio2Face 按键用于单步调试，点击*Audio2Face*按键，可以在下方的*Face Data Path*中自动填入生成的面部动画数据
    - Face Data Path用于单步调试，如果想使用在外部采集/生成的面部动画数据（npz、csv），可以在*Face Data Path*中手动更改文件路径
    - Import Face Anim按键用于单步调试，点击*Import Face Anim*，即可将选定的面部动画数据施加于当前设定的Target Face Mesh，每次点击都可以自动覆盖之前的生成结果

    ![image.png](https://prod-files-secure.s3.us-west-2.amazonaws.com/377f2602-1acb-4b9b-b8c9-0b4eab3f6e7a/0d2728ac-4230-4ec9-a297-3f20e849a01c/image.png)
